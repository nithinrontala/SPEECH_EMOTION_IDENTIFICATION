# SPEECH_EMOTION_IDENTIFICATION
•	DATASET INFORMATION
The CREMA-D data collection contains 7,442 original clips from 91 performers. These video feature 48 male and 43 female performers ranging in age from 20 to 74 and representing a wide range of races and ethnicities (African America, Asian, Caucasian, Hispanic, and Unspecified).

The actors read from a list of 12 phrases. The phrases were given with one of six distinct emotions and four different emotion degrees (Anger, Disgust, Fear, Happy, Neutral, and Sad) (Low, Medium, High and Unspecified).
The emotion and em otion levels were judged by participants based on the integrated audiovisual presentation, the video alone, and the audio alone. Because of the enormous number of ratings required, this effort was crowd-sourced, with a total of 2443 people rating 90 unique clips apiece.30 audio, 30 visual, and 30 audio-visual. 95% of the clips have more than 7 ratings.
•	Emotions Available
              anger
	            disgust
           	  fear
	            happy
        	    sad
            	neutral
•	Python Packages
                           Librosa
                          Numpy
                          Pandas
                          Scikit-learn
                         Seaborn
                         Matplotlib
•	Feature Extraction
Feature extraction is the main part of the speech emotion recognition system. It is basically accomplished by changing the speech waveform to a form of parametric representation at a relatively lesser data rate.
In this repository, we used the most often used librosa library features, such as:

MFCC
•	Neural Network 

The LSTM Network


